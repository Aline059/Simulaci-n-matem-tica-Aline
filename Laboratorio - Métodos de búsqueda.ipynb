{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28086fca-2cdd-41ac-b7bf-bc1af9f759a2",
   "metadata": {},
   "source": [
    "# Laboratorio: Métodos de búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19abc1-82f0-4f28-9493-468e4227c14f",
   "metadata": {},
   "source": [
    "En las clases anteriores creaste códigos para realizar búsquedas aleatorias (Simulated Annealing) y búsquedas dirigidas (Optimización Bayesiana). Estos métodos de búsqueda se utilizan para facilitar el proceso de optimización de funciones objetivos compleja y costosas de computar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038474ce-6e2f-4d45-895a-bb17f7c8871d",
   "metadata": {},
   "source": [
    "En este laboratorio usaremos el dataset de los diferentes tipos de iris, y sus longitudes y anchos de pétalos y sépalos. Utilizaremos un RandomForest para crear un modelo de clasificación y el métrico F1 para decidir cuál es el mejor modelo de acuerdo a lo que tenemos disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04956ea-14f4-419e-adf8-add3b81da443",
   "metadata": {},
   "source": [
    "1. Carga el dataset de Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad912f2-1359-437e-af68-3c8cca8d1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_iris(return_X_y=True) #longitud de 150 cada uno "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97ad91-d82b-491c-ac5d-be6f872c5334",
   "metadata": {},
   "source": [
    "2. Importa el archivo `Bosque.py`.\n",
    "\n",
    "Este archivo contiene la función `RegresionBosque`, que recibe:\n",
    "- X: las características independientes\n",
    "- y: la variable de respuesta\n",
    "- árboles: cantidad total de árboles\n",
    "- profundidad de bosque: niveles de profundidad del bosque\n",
    "\n",
    "Su salida es:\n",
    "- modelo: El objeto con el modelo ajustado\n",
    "- f1: El métrico que califica qué tan bueno es el modelo que se ajustó.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23f875f1-a72a-4a57-8355-16d6bb9fb33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Bosque\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 48, 2) # X, y ya te los dan \n",
    "f1 #hmmmm incluso con los mismos valores de entrada f1 es aleatorio cada vez \n",
    "#La función sólo puede recibir valores individuales enteros del 1 al infinito para árboles y profundidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb48be9-cfaf-4fc1-b13b-611e5ae5cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En base a los valores de arbol y profundidad que yo meto, me regresa su respectivo valor de f1, es decir mi variable de salida, lo que quiero predecir. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac2825-33ac-4919-9ccb-8324701ce99f",
   "metadata": {},
   "source": [
    "### Actividad 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb265f-9ccf-4fb4-b8c0-8fe221ea534c",
   "metadata": {},
   "source": [
    "Inicializa un espacio con 5 muestras en nuestro dominio de variables independientes:\n",
    "- árboles: números enteros entre 5 y 50.\n",
    "- profundidad: números enteros entre 2 y 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7c396-af97-49a6-828e-c5d63c1b6999",
   "metadata": {},
   "source": [
    "Utiliza optimización Bayesiana para encontrar la combinación de árboles y profundidad que **maximice** el métrico F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed57828-10bf-4435-b9ad-d52b3cbd7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las variables independientes son arbol y profundidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e563392-4509-4d70-9cb6-adca944d2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#máximo teórico, en donde tengo el punto más alto posible. Osea el máx del intervalo de confianza y ponemos un punto ahí, pero luego volvemos a checar el intervalo \n",
    "import Bosque\n",
    "import numpy as np \n",
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "arboles = np.random.randint(5,51,5) #randint no incluye el limite superior \n",
    "profundidad = np.random.randint(2,11,5)\n",
    "\n",
    "arboles_vec = np.random.randint(5,51,5).reshape([-1,1]) #usar -1 es como decirle, que el número de filas sea el index de la ultima posición, osea una fila por cada valor \n",
    "profundidad_vec = np.random.randint(2,11,5).reshape([-1,1]) \n",
    "\n",
    "\n",
    "m1,z1 = Bosque.RegresionBosque(X, y, arboles[0], profundidad[0])\n",
    "m2,z2 = Bosque.RegresionBosque(X, y, arboles[1], profundidad[1])\n",
    "m3,z3 = Bosque.RegresionBosque(X, y, arboles[2], profundidad[2])\n",
    "m4,z4 = Bosque.RegresionBosque(X, y, arboles[3], profundidad[3])\n",
    "m5,z5 = Bosque.RegresionBosque(X, y, arboles[4], profundidad[4])\n",
    "\n",
    "valores_z = np.array([z1, z2, z3, z4, z5]).reshape([-1,1]) #mis valores f1, de salida, lo que quiero predecir \n",
    "\n",
    "X_var_independientes = np.hstack((arboles_vec, profundidad_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab5beec8-4457-47dc-849d-42e476716f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  2],\n",
       "       [15, 10],\n",
       "       [10,  6],\n",
       "       [15,  6],\n",
       "       [18,  8]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var_independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9deda91-aad5-4328-a8f3-1fafd1495198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95555556],\n",
       "       [0.94444444],\n",
       "       [0.95555556],\n",
       "       [0.95555556],\n",
       "       [0.93333333]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1fe7871-3497-4e14-8422-3d41f4e498f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#el chiste es usar estos puntos que ya tengo para hacer una regresión Gaussiana que me pueda predecir valores de f1 (z) para otros puntos \n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor \n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "kernel = 1.0*RBF(length_scale=1)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer =10).fit(X_var_independientes, valores_z) \n",
    "\n",
    "x_arboles = np.linspace(5,50,1000).reshape([-1,1]) #linspace sí inlcuye el límite superior \n",
    "x_profundidad = np.linspace(2,10,1000).reshape([-1,1])\n",
    "x_prueba = np.hstack((x_arboles ,x_profundidad))\n",
    "\n",
    "y_pred, y_std = gp.predict(x_prueba, return_std=True) \n",
    "\n",
    "y_pred_low = y_pred - 1.96*y_std\n",
    "y_pred_high = y_pred + 1.96*y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59fcb9c1-b7b1-466c-9a8b-f7db9b1863a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = np.argmax(y_pred) \n",
    "i_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ace814da-3aa7-4c85-8778-cc9faf8a541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555698208646"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[246] #Para comprobar en cuánto están los otros valores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4190bdf-3307-412e-a575-1ff3ed5f99cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555738913952"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[i_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d872e139-f948-4843-8479-24208d30a5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.18018018,  5.58758759])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_prueba[i_max] #....no hay decimales de árboles. No se debe usar el linspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae7e931f-f625-4cee-b90f-969b37a33639",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arboles = np.random.randint(5,51,1000).reshape([-1,1]) \n",
    "x_profundidad = np.random.randint(2,11,1000).reshape([-1,1])\n",
    "x_prueba = np.hstack((x_arboles ,x_profundidad))\n",
    "\n",
    "y_pred, y_std = gp.predict(x_prueba, return_std=True) \n",
    "\n",
    "y_pred_low = y_pred - 1.96*y_std\n",
    "y_pred_high = y_pred + 1.96*y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "929c7a85-4b85-470e-8344-d898b93e40fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = np.argmax(y_pred) \n",
    "i_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2273208d-a878-49c8-8c8e-5bbe622f9345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555722863609"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[557]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adff8556-3b28-4b40-8570-5f1c8f8b934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9555555774004034, array([28,  2]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[212], x_prueba[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ffa694d-9c11-488e-a583-3281fa364216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\21ali\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    }
   ],
   "source": [
    "#Lo voy a repetir 10 veces para maximizar\n",
    "#o es hacerlo 10 veces sin aumentarle a la matriz de variables independientes? \n",
    "\n",
    "for i in range(10): \n",
    "    kernel = 1.0*RBF(length_scale=1)\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer =10).fit(X_var_independientes, valores_z) \n",
    "    x_arboles = np.random.randint(5,51,1000).reshape([-1,1]) \n",
    "    x_profundidad = np.random.randint(2,11,1000).reshape([-1,1])\n",
    "    x_prueba = np.hstack((x_arboles ,x_profundidad))\n",
    "    y_pred, y_std = gp.predict(x_prueba, return_std=True) \n",
    "    y_pred_low = y_pred - 1.96*y_std\n",
    "    y_pred_high = y_pred + 1.96*y_std\n",
    "    i_max = np.argmax(y_pred) \n",
    "    X_var_independientes = np.vstack((X_var_independientes, x_prueba[i_max]))\n",
    "    valores_z = np.vstack((valores_z, [[y_pred[i_max]]])) \n",
    "    \n",
    "#termina el ciclo pero quiero que me haga la regresión una vez más con las últimas matrices obtenidas \n",
    "kernel = 1.0*RBF(length_scale=1)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer =10).fit(X_var_independientes, valores_z) \n",
    "x_arboles = np.random.randint(5,51,1000).reshape([-1,1]) \n",
    "x_profundidad = np.random.randint(2,11,1000).reshape([-1,1])\n",
    "x_prueba = np.hstack((x_arboles ,x_profundidad))\n",
    "y_pred, y_std = gp.predict(x_prueba, return_std=True) \n",
    "y_pred_low = y_pred - 1.96*y_std\n",
    "y_pred_high = y_pred + 1.96*y_std\n",
    "i_max = np.argmax(y_pred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee25502b-a56f-4dc7-b4ea-e76e53311506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9687587949170933, array([48,  2]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[i_max], x_prueba[i_max] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3856e-d7f4-4099-9008-162027e21182",
   "metadata": {},
   "source": [
    "La respuesta al problema de la actividad 1 después de realizar el proceso Gaussiano es que el mayor valor del metrico F1 se obtiene con la combinación de 48 árboles y 2 de profunidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc5cef7-9ec9-4d9f-89ab-955192dc087b",
   "metadata": {},
   "source": [
    "Sin embargo, se podría haber utilizado el linspace de manera más inteligente en lugar de usar random.randint al ponerlo como np.linspace(5,50,46). El linspace al tener la característica de escoger puntos igual de espaciados en el rango, tomaría un espacio de 1 entero entre cada número si se pusiera que se quieren exactamente la cantidad de números que hay entre los límites. En este caso 46. Esto habría evitado tener que trabajar con números enteros desde el inicio. Una implementación de esto se verá en el proyecto 3 que se entregará para la materia :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0bf187-6483-4fc7-84d6-45e6759f5282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_iris(return_X_y=True) #longitud de 150 cada uno \n",
    "\n",
    "import Bosque\n",
    "sup, fra = Bosque.RegresionBosque(X, y, 48, 2) \n",
    "fra \n",
    "#esta parte del código fue para hacer la prueba de que en efecto f1 diera el resultado que encontré con los valores óptimos de árboles y profundidad \n",
    "#y me di cuenta que incluso con los mismso valores el parámero f1 es medio aleatorio...siempre cambia. \n",
    "#por lo que  creo que si hubiera utilizado el linspace para tener sólo 46 puntos por ejemplo, podría no haber llegado nunca al valor de 0.96\n",
    "#en este caso creo que el usar el randint con 1000 puntos en cada iteración del ciclo de alguna manera me ayudó a llegar a ese resultado de 0.96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80f5832d-28f3-4df0-9820-cff1c5e00bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Bosque\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 48, 2) \n",
    "f1\n",
    "#como que es por prob y por más veces que corría la celda no lográ llegar a 0.96. Sin embargo al inicio del código se ve que tuve la suerte \n",
    "#de que con esos mismos valores de árboles y profundidad saliera 0.96... en la prueba "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e083a3c-fa68-4942-b5d3-f1f7130b4fbb",
   "metadata": {},
   "source": [
    "### Actividad 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817a47c-0081-4376-b222-c65735f4ab9d",
   "metadata": {},
   "source": [
    "Inicializa 2 vectores con posibles valores para las variables independientes:\n",
    "- árboles: números enteros entre 5 y 50\n",
    "- profundidad: números enteros entre 2 y 10\n",
    "\n",
    "Utiliza el algoritmo de Simulated Annealing que siga el siguiente orden:\n",
    "- Elige un punto de partida para las variables.\n",
    "- Selecciona al azar una de las dos para modificarlas.\n",
    "- Selecciona un elemento al azar de la lista que contiene los posibles valores de esa variable.\n",
    "- Sigue el algoritmo ($p$ y $q$) para decidir si usas esa combinación nueva o si mantienes la anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a327de08-5976-45dc-b2b7-0f2131648677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " array([[20],\n",
       "        [39],\n",
       "        [14],\n",
       "        [39],\n",
       "        [21]]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectores de cuántos valores? \n",
    "ac2_vec_arboles = np.random.randint(5,51,5).reshape([-1,1])\n",
    "ac2_vec_profundidad = np.random.randint(2,11,5).reshape([-1,1])\n",
    "ac2_vec_arboles[2][0], ac2_vec_arboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6286fe8-ec56-4871-9c31-8d4d3ca4c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.95555556],\n",
       "        [0.95555556],\n",
       "        [0.95555556],\n",
       "        [0.95555556],\n",
       "        [0.94444444]]),\n",
       " array([[20,  6],\n",
       "        [39,  7],\n",
       "        [14,  6],\n",
       "        [39,  6],\n",
       "        [21,  4]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_,f1_z1 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[0][0], ac2_vec_profundidad[0][0])\n",
    "_,f1_z2 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[1][0], ac2_vec_profundidad[1][0])\n",
    "_,f1_z3 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[2][0], ac2_vec_profundidad[2][0])\n",
    "_,f1_z4 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[3][0], ac2_vec_profundidad[3][0])\n",
    "_,f1_z5 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[4][0], ac2_vec_profundidad[4][0])\n",
    "\n",
    "f1_R1 = np.array([f1_z1,f1_z2,f1_z3,f1_z4,f1_z5]).reshape([-1,1]) \n",
    "\n",
    "X_R1 = np.hstack((ac2_vec_arboles, ac2_vec_profundidad))\n",
    "\n",
    "f1_R1, X_R1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0e1bcf2-585b-4a43-8ab5-816d1de81f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora primero calculo el valor máximo de f1 para mi conjunto R1 \n",
    "def f1_max_para_R1(f1_R1, X_R1): \n",
    "    kernel_R1 = 1.0*RBF(length_scale=1)\n",
    "    gp_R1 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer =10).fit(X_R1 , f1_R1) \n",
    "    x_arboles_R1 = np.random.randint(5,51,1000).reshape([-1,1]) \n",
    "    x_profundidad_R1 = np.random.randint(2,11,1000).reshape([-1,1])\n",
    "    x_prueba_R1 = np.hstack((x_arboles_R1 ,x_profundidad_R1))\n",
    "    y_pred_R1, y_std_R1 = gp.predict(x_prueba_R1, return_std=True) \n",
    "    y_pred_low_R1 = y_pred_R1 - 1.96*y_std_R1\n",
    "    y_pred_high_R1 = y_pred_R1 + 1.96*y_std_R1\n",
    "    i_max_R1 = np.argmax(y_pred_R1)\n",
    "    return y_pred_R1[i_max_R1], x_prueba_R1[i_max_R1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61405614-45f0-45ad-824b-f3f06a137eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9690658681831295, array([50,  2]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_max_para_R1(f1_R1, X_R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18260a63-95db-407f-a4de-f425cf23d923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.95555556],\n",
       "        [0.95555556],\n",
       "        [0.95555556],\n",
       "        [0.95555556],\n",
       "        [0.94444444]]),\n",
       " array([[20,  6],\n",
       "        [39,  7],\n",
       "        [14,  6],\n",
       "        [39,  6],\n",
       "        [21,  4]]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_R1, X_R1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3caabfa2-893c-4da8-9e99-dfe1aed7297c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[20],\n",
       "        [39],\n",
       "        [14],\n",
       "        [39],\n",
       "        [21]]),\n",
       " array([[6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [6],\n",
       "        [4]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac2_vec_arboles, ac2_vec_profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fde395d2-32a8-48ab-a7a4-ebddd9cfb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora modifico mis vectores iniciales para tener los de R2 \n",
    "vector_a_modificar = np.random.choice([\"arboles\",\"profundidad\"])\n",
    "indice_a_modificar = np.random.choice([0,1,2,3,4])\n",
    "if vector_a_modificar == \"arboles\": \n",
    "    nuevo_valor = np.random.randint(5,51)\n",
    "    ac2_vec_arboles[indice_a_modificar][0] = nuevo_valor\n",
    "    \n",
    "if  vector_a_modificar == \"profundidad\": \n",
    "    nuevo_valor = np.random.randint(2,11)\n",
    "    ac2_vec_profundidad[indice_a_modificar][0] = nuevo_valor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "04808323-0f67-4660-a69d-9b8826e0fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[20],\n",
       "        [30],\n",
       "        [14],\n",
       "        [39],\n",
       "        [21]]),\n",
       " array([[6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [6],\n",
       "        [4]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac2_vec_arboles, ac2_vec_profundidad #se cambió el 39 por 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "239fa243-bd6d-4ec4-860a-2eae65cea710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.96666667],\n",
       "        [0.95555556],\n",
       "        [0.93333333],\n",
       "        [0.95555556],\n",
       "        [0.93333333]]),\n",
       " array([[20,  6],\n",
       "        [30,  7],\n",
       "        [14,  6],\n",
       "        [39,  6],\n",
       "        [21,  4]]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,f1_z1_R2 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[0][0], ac2_vec_profundidad[0][0])\n",
    "_,f1_z2_R2 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[1][0], ac2_vec_profundidad[1][0])\n",
    "_,f1_z3_R2 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[2][0], ac2_vec_profundidad[2][0])\n",
    "_,f1_z4_R2 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[3][0], ac2_vec_profundidad[3][0])\n",
    "_,f1_z5_R2 = Bosque.RegresionBosque(X, y, ac2_vec_arboles[4][0], ac2_vec_profundidad[4][0])\n",
    "\n",
    "f1_R2 = np.array([f1_z1_R2,f1_z2_R2,f1_z3_R2,f1_z4_R2,f1_z5_R2]).reshape([-1,1]) \n",
    "\n",
    "X_R2 = np.hstack((ac2_vec_arboles, ac2_vec_profundidad))\n",
    "\n",
    "f1_R2, X_R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00442559-60d2-440a-9ba0-5217ea775ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora primero calculo el valor máximo de f1 para mi conjunto R2 (el nuevo) \n",
    "def f1_max_para_R2(f1_R2, X_R2): \n",
    "    kernel_R2 = 1.0*RBF(length_scale=1)\n",
    "    gp_R2 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer =10).fit(X_R2 , f1_R2) \n",
    "    x_arboles_R2 = np.random.randint(5,51,1000).reshape([-1,1]) \n",
    "    x_profundidad_R2 = np.random.randint(2,11,1000).reshape([-1,1])\n",
    "    x_prueba_R2 = np.hstack((x_arboles_R2 ,x_profundidad_R2))\n",
    "    y_pred_R2, y_std_R2 = gp.predict(x_prueba_R2, return_std=True) \n",
    "    y_pred_low_R2 = y_pred_R2 - 1.96*y_std_R2\n",
    "    y_pred_high_R2 = y_pred_R2 + 1.96*y_std_R2\n",
    "    i_max_R2 = np.argmax(y_pred_R2)\n",
    "    return y_pred_R2[i_max_R2], x_prueba_R2[i_max_R2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "192793f5-63f2-49e0-9566-6329b6b17a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9690658681831295, array([50,  2]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_max_para_R2(f1_R2, X_R2) #mmmmm....sale exactamente igual :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fb88c-90f0-4af8-a7c7-d565204a1000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
